{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downscaling ECOSTRESS LST using Sentinel-2 VSWIR products at High Resolution (<20m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notebook : Quentin Dehaene, mentored by Glynn Hulley    \n",
        "Original Python Implementation : [Radoslaw Guzinski](https://github.com/radosuav/pyDMS)  \n",
        "Original Implemenation : [Gao et al.](https://doi.org/10.3390/rs4113287)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Questions : quentin.dehaene@jpl.nasa.gov   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import cell\n",
        "from osgeo import gdal\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import os\n",
        "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
        "import rasterio.mask\n",
        "import rasterio.windows\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "from datetime import datetime\n",
        "from sentinelhub import (SHConfig, DataCollection, SentinelHubCatalog, SentinelHubRequest, BBox, bbox_to_dimensions, CRS, MimeType, Geometry,MosaickingOrder)\n",
        "import rioxarray as rxr\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "from pyDMS_master.run_pyDMS import *\n",
        "\n",
        "# If you recieve a No module named '...' error, it is likely because you haven't installed all the necessary packages (cf tutorial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, HR will refer to the high-resolution image used to train our regression algorithm. LR will refer to the coarse resolution image that we are trying to upsample, in our case the ECOSTRESS LST at 70m.\n",
        "\n",
        "The first step is to reproject and subset LR to HR Coordinates Reference System (CRS) and extent. This means that the result, and all images in the process will be in the HR CRS and will share its extent. Even if it implies padding a smaller LR with nodata values to match the extents. Reversely, all the images bigger than HR would be cut.\n",
        "\n",
        "The second step consists in resampling HR to the coarse resolution of LR (producing a temporary file). In the process, we compute the homogeneity inside each coarse resolution pixel. We are computing here how “pure” each coarse pixel is, i.e. how different are high resolution pixels that compose the coarse resolution pixel. For instance, if a coarse pixel is on a field, then it is very likely that all the high-resolution pixels composing that coarse pixel will be very similar because the material will be homogenous. However, in cities, larger pixels may actually be composed of several materials (asphalt roof, sidewalk, vegetation) and therefore be far less homogenous. We’ll use this homogeneity as a weight factor in our training.\n",
        "\n",
        "The default threshold is 80%, meaning that the 20% of pixels that are the least homogenous will be disregarded for the training.\n",
        "\n",
        "We can now start the training and fit the resampled HR to the LR.\n",
        "\n",
        "For those interested in how the tree is conceived:\n",
        "\n",
        "We are training a bagging of an ensemble of regression trees. Each of these trees is slightly more complicated than the usual regression tree. The principle of the tree is classic: each node is built to minimize the mean square error (MSE), hence each rule is made to split the data into different categories (the number of leaves being a parameter chosen here) and then we affect a value to each datum (each pixel in our case) falling into that category. The difference here lays in the way we determine the target value on each leaf: instead of giving the average of the y values (i.e. the LST) to all features in the leaf, we apply a Bayesian linear regression. We also have a limit as to how far from the training samples we can extrapolate when we predict with our regression tree.\n",
        "\n",
        "The tree is thus trained using the resampled HR as $X_{train}$ and the reprojected LR as $y_{train}$ (ground truth). Our tree is trained at low resolution, because it is at this resolution that we have what we know to be true and that we can actually establish a link between reflectance and LST.\n",
        "\n",
        "Now that the tree is trained, we can use it to make predictions. For that, we use the provided HR as X. We obtain a first prediction of the LST ($y_{pred}$) at the high resolution.\n",
        "\n",
        "Then, comes the residual analysis: We compute the residual (y-$y_{pred}$) at the coarse resolution. We compare our predicted LST, resampled at the coarse resolution, to the original LR. For that, we don’t actually compare the LST but the $LST^4$ which is proportional to the exitance. It makes more sense, since physically, temperature doesn’t have to be conserved in the sharpening, the energy does. And sensors don’t measure temperature but radiance.\n",
        "\n",
        "The final step is to smooth the residual, resample it to the high resolution, and sum it with the $y_{pred}$, our LST predicted. We now have a final LST prediction that verifies that the average radiance of all the high-resolution pixels composing a coarse pixel is equal to the radiance in the original LST.\n",
        "\n",
        "This is our downscaled image that we were looking for.\n",
        "\n",
        "I would like to note that there are two other sharpening techniques implemented in the pyDMS code, developed (and still being developed as of July 2024) by R. Guzinski. All the steps are the same, the only difference is the regression tree itself. There is on one hand, the Neural Network regressor i.e. instead of the tree presented here, we are using an MLP tree from [scikit-learn](https://github.com/aigamedev/scikit-neuralnetwork). On the other hand, is the one that’s actually closer to the original proposition of Gao, it is based on a [Cubist](https://www.rulequest.com/cubist-unix.html) regressor.\n",
        "\n",
        "The results don’t differ significantly from what I have tried, I went to the oldest/default (and hence more fool-proofed) but I welcome any feedback from your end.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up and preprocessing\n",
        "\n",
        "This whole notebook is actually a wrap over the original run_pyDMS. It is intended to render the sharpening easy and automatic by dealing with an entire folder at a time. Indeed, when interested in an area, we are looking at a series of images, a heatwave week, a summer month or more. The point here is to have all the files from your [AppEEARS](https://appeears.earthdatacloud.nasa.gov/) request in the same folders : one folder for the Land Surface Temperature files and another for the Quality Control files. They will all be downscaled using a single Sentinel 2 VSWIR image after being preprocessed earlier in the code.  \n",
        "The output files, will all be written in one folder in the GEOTIFF format, that you can use in any GIS software. For each image a residual GEOTIFF will also be produced, but in most cases you can ignore these files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For convenience, all of the inputs requested from the user are grouped the next 3 cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This cell is made for you to type the directories you want the dowloaded products and results to be written into, you also have to indicate the path towards the ECOSTRESS files dowloaded previously. When you type a directory, it shouldn't include the final / or \\ (otherwise you will get a syntax error)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose your output folder for the downloaded Sentinel-2 products\n",
        "s2_output_folder = r''\n",
        "# Folder where all the ECOSTRESS Quality Control files are located. This can remain empty if you don't have any QC file\n",
        "QC_dir = r''\n",
        "# Folder where all the ECOSTRESS Cloud mask files are located. It is required to download and the the cloud mask if you are using collection 2. \n",
        "cloud_dir = r''\n",
        "# Folder where all the ECOSTRESS LST files are located for the scene of interest\n",
        "lst_dir = r''\n",
        "# If your ECOSTRESS LST files are already scaled, then you can type here the directory in which they are located. If they are not scaled, you can leave this empty, they'll be scaled and placed in a directory in a following cell.\n",
        "lst_dir_sc = r''\n",
        "# Folder where all the sharpened ECOSTRESS LST files will be written for the scene of interest\n",
        "dst_dir = r''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Downloading Sentinel 2 product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All the Sentinel data is free to access, but it requires to create an account to download data.\n",
        "First, if you don't have an account on [Copernicus Data Space](https://dataspace.copernicus.eu/), create one and log in.  \n",
        "Now access your User Settings : My Account > DashBoard > User Settings (bottom left)  \n",
        "Create a new OAuth client. And save your newly given token ID and password (called a secret here).  \n",
        "\n",
        "If you encounter problem with the S2 download please refer to this [Documentation](https://sentinelhub-py.readthedocs.io/en/latest/index.html) or to this [Copernicus Web page](https://dataspace.copernicus.eu/news/2023-9-28-accessing-sentinel-mission-data-new-copernicus-data-space-ecosystem-apis).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insert your logs for the OAuth Copernicus Data Space created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = SHConfig()\n",
        "config.sh_base_url = 'https://sh.dataspace.copernicus.eu'\n",
        "config.sh_token_url = 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token'\n",
        "config.sh_client_id ='' # type you client id\n",
        "config.sh_client_secret ='' # type your client secret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define your bounding box, its resolution and the time interval in which you want the data. The bounding box is limited to 2500 pixels, you will recieve an error if the request is larger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The coordinates of the bounding box of your choosing, in lat lon : (xmin,ymin,xmax,ymax)\n",
        "# Use the http://bboxfinder.com to find your box easily (already in the right order)\n",
        "aoi_coords_wgs_84 = (-87.972336,41.769775,-87.606354,42.013591) # example\n",
        "\n",
        "# Choose the resolution of the Sentinel data in meters 10 or 20, this will be the final resolution of the downscaled image\n",
        "s2_res = 20\n",
        "\n",
        "# Render the coordinates usable by the Copernicus API\n",
        "aoi_bbox = BBox(bbox = aoi_coords_wgs_84,crs=CRS.WGS84)\n",
        "aoi_size = bbox_to_dimensions(aoi_bbox,resolution = s2_res)\n",
        "\n",
        "print(f\"Image shape at {s2_res} m resolution: {aoi_size} pixels\") # The size of the box is limited to 2500 pixels in each direction\n",
        "if (aoi_size[0]>2499 or aoi_size[1]>2499) :\n",
        "    raise(ValueError(\"The box is limited to 2500 pixels in each direction, try again with a smaller bounding box.\"))\n",
        "\n",
        "\n",
        "# Choose your time interval (beginning, end) in the format (YYYY-MM-DD). You'll receive a S2 image from the tile with the lowest cloud coverage available in the interval :\n",
        "interval = (\"2023-06-01\", \"2023-08-01\") # example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the S2 image with the previously defined parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Request scripts, based off the sentinelhub documentation\n",
        "# This script will be used to download all the S2 whose resolution is 20m or below\n",
        "evalscript_all_bands_u20 = \"\"\"\n",
        "    //VERSION=3\n",
        "    function setup() {\n",
        "        return {\n",
        "            input: [{\n",
        "                bands: [\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B11\",\"B12\"],\n",
        "                units: \"REFLECTANCE\"\n",
        "\n",
        "            }],\n",
        "            output: {\n",
        "                bands: 10,\n",
        "                sampleType: \"FLOAT32\"\n",
        "            }\n",
        "        };\n",
        "    }\n",
        "\n",
        "    function evaluatePixel(sample) {\n",
        "        return [sample.B02,\n",
        "                sample.B03,\n",
        "                sample.B04,\n",
        "                sample.B05,\n",
        "                sample.B06,\n",
        "                sample.B07,\n",
        "                sample.B08,\n",
        "                sample.B8A,\n",
        "                sample.B11,\n",
        "                sample.B12];\n",
        "    }\n",
        "\"\"\"\n",
        "# This script will be used to download all the S2 whose resolution is 10m\n",
        "evalscript_all_bands_u10 = \"\"\"\n",
        "    //VERSION=3\n",
        "    function setup() {\n",
        "        return {\n",
        "            input: [{\n",
        "                bands: [\"B02\",\"B03\",\"B04\",\"B08\"],\n",
        "                units: 'REFLECTANCE'\n",
        "            }],\n",
        "            output: {\n",
        "                bands: 4,\n",
        "                sampleType: \"FLOAT32\"\n",
        "            }\n",
        "        };\n",
        "    }\n",
        "\n",
        "    function evaluatePixel(sample) {\n",
        "        return [sample.B02,\n",
        "                sample.B03,\n",
        "                sample.B04,\n",
        "                sample.B08,];\n",
        "    }\n",
        "\"\"\"\n",
        "# Request the data at 20m\n",
        "if s2_res == 20 :\n",
        "    request_all_bands_u20 = SentinelHubRequest(\n",
        "        data_folder=s2_output_folder,\n",
        "        evalscript=evalscript_all_bands_u20,\n",
        "        input_data=[\n",
        "            SentinelHubRequest.input_data(\n",
        "                data_collection = DataCollection.SENTINEL2_L2A.define_from(\"s2l2a\", service_url=config.sh_base_url),\n",
        "                time_interval = interval,\n",
        "                mosaicking_order=MosaickingOrder.LEAST_CC, # selecting the tile in the interval with the least cloud coverage\n",
        "\n",
        "            )\n",
        "        ],\n",
        "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
        "        bbox=aoi_bbox,\n",
        "        size=aoi_size,\n",
        "        config=config,\n",
        "    )\n",
        "    resp = request_all_bands_u20.save_data(show_progress = True)\n",
        "# Request the data at 10m\n",
        "elif s2_res == 10 :\n",
        "    request_all_bands_u10 = SentinelHubRequest(\n",
        "        data_folder=s2_output_folder,\n",
        "        evalscript=evalscript_all_bands_u10,\n",
        "        input_data=[\n",
        "            SentinelHubRequest.input_data(\n",
        "                data_collection = DataCollection.SENTINEL2_L2A.define_from(\"s2l2a\", service_url=config.sh_base_url),\n",
        "            time_interval = interval,\n",
        "                mosaicking_order = MosaickingOrder.LEAST_CC\n",
        "            )\n",
        "        ],\n",
        "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
        "        bbox=aoi_bbox,\n",
        "        size=aoi_size,\n",
        "        config=config,\n",
        "    )\n",
        "\n",
        "    resp = request_all_bands_u10.save_data(show_progress= True)\n",
        "else :\n",
        "    raise(ValueError('Unexpected resolution please change it to 10 or 20'))\n",
        "\n",
        "# Rename the downloaded files for clarity\n",
        "dirs = [d for d in os.listdir(s2_output_folder)]\n",
        "\n",
        "most_recent_dir = max(dirs, key=lambda d: os.path.getmtime(os.path.join(s2_output_folder, d)))\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "new_name = f\"S2_request_{timestamp}\"\n",
        "old_path = os.path.join(s2_output_folder, most_recent_dir)\n",
        "new_path = os.path.join(s2_output_folder, new_name)\n",
        "os.rename(old_path, new_path)\n",
        "beg = interval[0]\n",
        "end = interval [1]\n",
        "for files in os.listdir(new_path):\n",
        "    if files.__contains__('response') :\n",
        "        os.rename(os.path.join(new_path,files),os.path.join(new_path,f\"S2_{s2_res}m_{beg}_{end}.tif\"))\n",
        "        hr_img_path = os.path.join(new_path,f\"S2_{s2_res}m_{beg}_{end}.tif\") # This file will be used to train our model and downscale the ECOSTRESS image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing ECOSTRESS Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following cells , we assume that you have the ECOSTRESS LST data products dowloaded alongside the Quality Control files if available (and cloud mask if you use Collection 2). Refer to the relative tutorial available [here](https://github.com/ECOSTRESS-Tutorials/) if you don't know how to obtain all the data you need. You can also use the alternate version of this notebook where it's all automatic.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocessing the QC files  \n",
        "\n",
        "The QC files are coded in 16 bits and thus can't be easily seen as a mask file. For convience, we write new Quality Flag (QF) files that respresent only the last two bits of the QC files. Then, there are only four possible values:  \n",
        "0 when the pixel is of best quality, 1 for nominal quality, 2 if a cloud is detected and 3 if the pixel is not produced. In the downscaling process, pixels with the last two values will be disregarded.   \n",
        "For more information on the QC files : https://lpdaac.usgs.gov/documents/423/ECO2_User_Guide_V1.pdf (section 2.4)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for file in os.listdir(QC_dir) : \n",
        "    if not file.endswith('QF.tif') and not file.endswith('.xml') :\n",
        "        file_qc = os.path.join(QC_dir,file)\n",
        "        with rasterio.open(file_qc,'r') as f_qc :\n",
        "            # Read the QC file, they are coded in 16 bits\n",
        "            qc_img = f_qc.read((1)) \n",
        "            qc_img[qc_img==-99999] = -1  # Nodata values are read as -99999, we change it to -1 so that the last two bits appear as 11 (which means pixel not produced) and be masked out in the end\n",
        "            # Select only the last two bits\n",
        "            qc_img_2 = qc_img & 0b11 \n",
        "            out_meta = f_qc.meta.copy()\n",
        "        # Write the last two bits in a new file\n",
        "        file_qf = file_qc.replace('.tif','_QF.tif')\n",
        "        with rasterio.open(file_qf,'w',**out_meta) as dst :\n",
        "            dst.write(qc_img_2,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scaling the ECOSTRESS LST to normal Kelvin scale.  \n",
        "  \n",
        "The LST product is actually scaled at 0.02, the GIS software takes that scale in account before display so you might not see it if you directly display on QGIS or ArcGIS. However, in Python it's easier to apply the scale rather than reading the metadata. \n",
        "The newly scaled files will be stored in a subdirectory in the LST folder.  \n",
        "  \n",
        "Skip this cell if your ECOSTRESS LST data is already scaled (multi day aggregate for instance)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If the scaled subdirectory doesn't already exist, create it\n",
        "lst_dir_sc = os.path.join(lst_dir,'scaled')\n",
        "if not os.path.exists(lst_dir_sc) :\n",
        "        os.mkdir(lst_dir_sc)\n",
        "\n",
        "# Scale each file\n",
        "for file in os.listdir(lst_dir) : \n",
        "        if file.endswith('.tif') :\n",
        "                with rasterio.open(os.path.join(lst_dir,file),'r') as lr_img: \n",
        "                        out_image=lr_img.read().astype('float32')\n",
        "                        out_image[out_image==0]=np.nan\n",
        "                        out_meta = lr_img.meta\n",
        "\n",
        "                out_meta.update({\"driver\": \"GTiff\",\n",
        "                        \"height\": out_image.shape[1],\n",
        "                        \"width\": out_image.shape[2],\n",
        "                        'dtype' :'float32'})\n",
        "\n",
        "                dst_path = os.path.join(lst_dir_sc,file)\n",
        "                with rasterio.open(dst_path,'w',**out_meta) as dst :\n",
        "                        # Apply the scale \n",
        "                        dst.write(out_image*0.02 +0.49)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upsampling using pyDMS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The preprocessing is now over. Let's sharpen using pyDMS. Use one of the following cells depending on the presence of Quality Control files and the desired extent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you have QC files and used the cell above to process them into QF files, you can use one these two following cells :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you use this cell, then the output extent will be the extent of the HR image. Thus, if the S2 image has a bigger extent than the ECOSTRESS image, then the edges will be padded with NaNs. If it is smaller then the sharpened image's extent will be the S2 image extent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "useDecisionTree = True # You could change this to False if you want to use the Neural Network intead of the Decision tree, not recommended\n",
        "\n",
        "files_sharpened = [] # list of the files sharpened\n",
        "\n",
        "# Loop through the directory of LST images scaled\n",
        "for file in os.listdir(lst_dir_sc) :\n",
        "    if file.endswith('.tif') :\n",
        "        if not os.path.exists(dst_dir) : # create the output directory if it doesn't exist already\n",
        "                        os.mkdir(dst_dir)\n",
        "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_S2.tif')) # destination path for the sharpened images\n",
        "\n",
        "        highResFilename = hr_img_path # the high resolution file is the downloaded s2 image\n",
        "        lowResFilename = os.path.join(lst_dir_sc,file) # the low resolution file is the scaled LST image\n",
        "\n",
        "        valid = False # Bool that states if a sence is \"valid\", not too cloudy or not presenting too many unproduced pixels (limit at 25% by default)\n",
        "        thresh= 0.75 # you can modify this value between 0 (if you accept any file, the unusable pixels will be masked) and 1 (if you only want to sharpen files where every pixel is usable)\n",
        "        \n",
        "        # If the scene to be downscaled is a scene from Collection 2\n",
        "        if file.__contains__('002') : \n",
        "            # The QC cloud bit being unreliable in Collection 2, we use the cloud mask directly as a validity mask\n",
        "            file_cl = 'cloud_mask'.join(file.rsplit('LST', 1))\n",
        "            lowResMaskFilename = os.path.join(cloud_dir,file_cl)\n",
        "            lowresflags = [0]\n",
        "            with rasterio.open(lowResMaskFilename,'r') as cld_msk : \n",
        "                cld_msk_arr = cld_msk.read(1)\n",
        "                mask_sz = cld_msk_arr.size\n",
        "                # Ensure that the scene to be sharpened isn't more than 25% cloudy\n",
        "            if np.count_nonzero(cld_msk_arr)<(1-thresh)*mask_sz :\n",
        "                valid = True\n",
        "        # If the scene to be downscaled belongs to Collection 1        \n",
        "        else : \n",
        "            # For Collection 1, we can rely on the QC (preprocessed earlier) file, no need to use the cloud mask\n",
        "            file_qc = 'QC'.join(file.rsplit('LST', 1))\n",
        "            file_qf = file_qc.replace('.tif','_QF.tif')\n",
        "            lowResMaskFilename = os.path.join(QC_dir,file_qf)        \n",
        "            with rasterio.open(lowResMaskFilename,'r') as mask :\n",
        "                mask_array = mask.read(1)\n",
        "                mask_sz = mask_array.size \n",
        "            lowresflags = [0,1]\n",
        "            # Ensure that the scene to be sharpened isn't more than 25% cloudy or invalid\n",
        "            if np.count_nonzero(mask_array==0) + np.count_nonzero(mask_array==1)>thresh*mask_sz :\n",
        "                valid = True\n",
        "        # Only downscale the files that are \"valid\" four our use case\n",
        "        if valid :     \n",
        "            commonOpts = {\"highResFiles\":               [highResFilename],\n",
        "                            \"lowResFiles\":                [lowResFilename],\n",
        "                            \"lowResQualityFiles\":         [lowResMaskFilename],\n",
        "                            \"lowResGoodQualityFlags\":     lowresflags, # flags for acceptable pixels\n",
        "                            \"cvHomogeneityThreshold\":     0, # the homogeneity threshold will be automatically computed\n",
        "                            \"movingWindowSize\":           0,\n",
        "                            \"disaggregatingTemperature\":  True} # we are dealing with LST\n",
        "            dtOpts =     {\"perLeafLinearRegression\":    True,\n",
        "                            \"linearRegressionExtrapolationRatio\": 0.25} # how much extrapolation we accept from the tree\n",
        "            sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
        "                            'activation':                 'tanh'}\n",
        "            nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
        "                            \"regressorOpt\":               sknnOpts}\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            if useDecisionTree: #  Regression tree\n",
        "                opts = commonOpts.copy()\n",
        "                opts.update(dtOpts)\n",
        "                disaggregator = DecisionTreeSharpener(**opts)\n",
        "            else: # Neural network\n",
        "                opts = commonOpts.copy()\n",
        "                opts.update(nnOpts)\n",
        "                disaggregator = NeuralNetworkSharpener(**opts)\n",
        "\n",
        "            # Training the tree\n",
        "            print(\"Training regressor...\")\n",
        "            disaggregator.trainSharpener()\n",
        "            # Applying the newly trained tree to the LR image\n",
        "            print(\"Sharpening...\")\n",
        "            downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
        "            # Performing residual analysis, to ensure that the unsharpened images's exitance is conserved\n",
        "            print(\"Residual analysis...\")\n",
        "            residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
        "                                                                            lowResMaskFilename,\n",
        "                                                                            doCorrection=True)\n",
        "            # Saving the image and its residual \n",
        "            print(\"Saving output...\")\n",
        "            highResFile = gdal.Open(highResFilename)\n",
        "            if correctedImage is not None:\n",
        "                outImage = correctedImage\n",
        "            else:\n",
        "                outImage = downscaledFile\n",
        "\n",
        "            outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
        "                                    outImage.GetGeoTransform(),\n",
        "                                    outImage.GetProjection(),\n",
        "                                    outputFilename)\n",
        "            residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
        "                                            residualImage.GetGeoTransform(),\n",
        "                                            residualImage.GetProjection(),\n",
        "                                            os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
        "                                            os.path.splitext(outputFilename)[1])\n",
        "            files_sharpened.append(file)\n",
        "            outFile = None\n",
        "            residualFile = None\n",
        "            downsaceldFile = None\n",
        "            highResFile = None\n",
        "\n",
        "            print(time.time() - start_time, \"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the ECOSTRESS image is completely included ( i.e. its extent is smaller) in the S2 image, then if desired, it is possible to cut the S2 image to the extent of the ECOSTRESS image, or to an extent of the user's choosing (which also has to be included). This might be useful for any mathematical postprocessing, such as computing RMSE or residual, because such an image would not contain any NaNs, and images would share same extents. To do so, use this cell :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "useDecisionTree = True # You could change this to False if you want to use the Neural Network intead of the Decision tree, not recommended\n",
        "\n",
        "files_sharpened = [] #list of the files sharpened\n",
        "\n",
        "# Loop through the directory of LST images\n",
        "for file in os.listdir(lst_dir_sc) :\n",
        "    if file.endswith('.tif') :\n",
        "        if not os.path.exists(dst_dir) :  # create the output directory if it doesn't exist already\n",
        "                        os.mkdir(dst_dir)\n",
        "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_S2_clipped.tif')) # destination path for the sharpened images\n",
        "        lowResFilename = os.path.join(lst_dir_sc,file)\n",
        "        lr_ds = rasterio.open(lowResFilename)\n",
        "\n",
        "        projwin = [lr_ds.bounds.left,lr_ds.bounds.top,lr_ds.bounds.right,lr_ds.bounds.bottom] # cut to the extent of the LR image\n",
        "        # projwin = [-118.08175, 34.16189, -117.998676, 34.112327] # example of a custom cutout over LA\n",
        "\n",
        "\n",
        "        hr_img_path_clipped = hr_img_path.replace('.tif',f'_clipped.tif') # also produces a clipped version of the HR image\n",
        "        ds = gdal.Open(hr_img_path)\n",
        "        ds = gdal.Translate(hr_img_path_clipped, ds, projWin = projwin)\n",
        "        ds = None\n",
        "        lr_ds = None\n",
        "        highResFilename = hr_img_path_clipped\n",
        "\n",
        "        valid = False # Bool that states if a sence is \"valid\", not too cloudy or not presenting too many unproduced pixels (limit at 25% by default)\n",
        "        thresh= 0.75 # you can modify this value between 0 (if you accept any file, the unusable pixels will be masked) and 1 (if you only want to sharpen files where every pixel is usable)\n",
        "        \n",
        "        # If the scene to be downscaled is a scene from Collection 2\n",
        "        if file.__contains__('002') : \n",
        "            # The QC cloud bit being unreliable in Collection 2, we use the cloud mask directly as a validity mask\n",
        "            file_cl = 'cloud_mask'.join(file.rsplit('LST', 1))\n",
        "            lowResMaskFilename = os.path.join(cloud_dir,file_cl)\n",
        "            lowresflags = [0]\n",
        "            with rasterio.open(lowResMaskFilename,'r') as cld_msk : \n",
        "                cld_msk_arr = cld_msk.read(1)\n",
        "                mask_sz = cld_msk_arr.size\n",
        "                # Ensure that the scene to be sharpened isn't more than 25% cloudy\n",
        "            if np.count_nonzero(cld_msk_arr)<(1-thresh)*mask_sz :\n",
        "                valid = True\n",
        "        # If the scene to be downscaled belongs to Collection 1        \n",
        "        else : \n",
        "            # For Collection 1, we can rely on the QC (preprocessed earlier) file, no need to use the cloud mask\n",
        "            file_qc = 'QC'.join(file.rsplit('LST', 1))\n",
        "            file_qf = file_qc.replace('.tif','_QF.tif')\n",
        "            lowResMaskFilename = os.path.join(QC_dir,file_qf)        \n",
        "            with rasterio.open(lowResMaskFilename,'r') as mask :\n",
        "                mask_array = mask.read(1)\n",
        "                mask_sz = mask_array.size \n",
        "            lowresflags = [0,1]\n",
        "            # Ensure that the scene to be sharpened isn't more than 25% cloudy or invalid\n",
        "            if np.count_nonzero(mask_array==0) + np.count_nonzero(mask_array==1)>thresh*mask_sz :\n",
        "                valid = True\n",
        "        # Only downscale the files that are \"valid\" four our use case\n",
        "        if valid :   \n",
        "            commonOpts = {\"highResFiles\":               [highResFilename],\n",
        "                            \"lowResFiles\":                [lowResFilename],\n",
        "                            \"lowResQualityFiles\":         [lowResMaskFilename],\n",
        "                            \"lowResGoodQualityFlags\":     lowresflags, # flags for acceptable pixels\n",
        "                            \"cvHomogeneityThreshold\":     0, # the homogeneity threshold will be automatically computed\n",
        "                            \"movingWindowSize\":           0,\n",
        "                            \"disaggregatingTemperature\":  True} # we are dealing with LST\n",
        "            dtOpts =     {\"perLeafLinearRegression\":    True,\n",
        "                            \"linearRegressionExtrapolationRatio\": 0.25} # how much extrapolation we accept from the tree\n",
        "            sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
        "                            'activation':                 'tanh'}\n",
        "            nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
        "                            \"regressorOpt\":               sknnOpts}\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            if useDecisionTree: #  Regression tree\n",
        "                opts = commonOpts.copy()\n",
        "                opts.update(dtOpts)\n",
        "                disaggregator = DecisionTreeSharpener(**opts)\n",
        "            else: # Neural network\n",
        "                opts = commonOpts.copy()\n",
        "                opts.update(nnOpts)\n",
        "                disaggregator = NeuralNetworkSharpener(**opts)\n",
        "\n",
        "            # Training the tree\n",
        "            print(\"Training regressor...\")\n",
        "            disaggregator.trainSharpener()\n",
        "            # Applying the newly trained tree to the LR image\n",
        "            print(\"Sharpening...\")\n",
        "            downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
        "            # Performing residual analysis, to ensure that the unsharpened images's exitance is conserved\n",
        "            print(\"Residual analysis...\")\n",
        "            residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
        "                                                                            lowResMaskFilename,\n",
        "                                                                            doCorrection=True)\n",
        "            # Saving the image and its residual \n",
        "            print(\"Saving output...\")\n",
        "            highResFile = gdal.Open(highResFilename)\n",
        "            if correctedImage is not None:\n",
        "                outImage = correctedImage\n",
        "            else:\n",
        "                outImage = downscaledFile\n",
        "\n",
        "            outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
        "                                    outImage.GetGeoTransform(),\n",
        "                                    outImage.GetProjection(),\n",
        "                                    outputFilename)\n",
        "            residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
        "                                            residualImage.GetGeoTransform(),\n",
        "                                            residualImage.GetProjection(),\n",
        "                                            os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
        "                                            os.path.splitext(outputFilename)[1])\n",
        "            files_sharpened.append(file)\n",
        "            outFile = None\n",
        "            residualFile = None\n",
        "            downsaceldFile = None\n",
        "            highResFile = None\n",
        "\n",
        "            print(time.time() - start_time, \"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You may wish to downscale images that don't have a QC or cloud mask file attached. For instance, if you're trying to sharpen an aggregated image such as a daytime average or if you're working with old images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you use this cell, then the output extent will be the extent of the HR image. Thus, if the S2 image has a bigger extent than the ECOSTRESS image, then the edges will be padded with NaNs. If it is smaller then the sharpened image's extent will be the S2 image extent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "useDecisionTree = True # You could change this to False if you want to use the Neural Network intead of the Decision tree, not recommended\n",
        "\n",
        "files_sharpened = [] #list of the files sharpened\n",
        "\n",
        "# Loop through the directory of LST images\n",
        "for file in os.listdir(lst_dir_sc) :\n",
        "    if file.endswith('.tif') :\n",
        "        if not os.path.exists(dst_dir) :  # create the output directory if it doesn't exist already\n",
        "                        os.mkdir(dst_dir)\n",
        "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_S2.tif')) # destination path for the sharpened images\n",
        "        lowResFilename = os.path.join(lst_dir_sc,file)\n",
        "        highResFilename = hr_img_path\n",
        "        lowResMaskFilename = ''\n",
        "\n",
        "\n",
        "        commonOpts = {\"highResFiles\":               [highResFilename],\n",
        "                        \"lowResFiles\":                [lowResFilename],\n",
        "                        \"lowResQualityFiles\":         [lowResMaskFilename],\n",
        "                        \"lowResGoodQualityFlags\":     [], #  no flags for acceptable pixels because no QF file to assert of the quality\n",
        "                        \"cvHomogeneityThreshold\":     0, # the homogeneity threshold will be automatically computed\n",
        "                        \"movingWindowSize\":           0,\n",
        "                        \"disaggregatingTemperature\":  True} # we are dealing with LST\n",
        "        dtOpts =     {\"perLeafLinearRegression\":    True,\n",
        "                        \"linearRegressionExtrapolationRatio\": 0.25} # how much extrapolation we accept from the tree\n",
        "        sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
        "                        'activation':                 'tanh'}\n",
        "        nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
        "                        \"regressorOpt\":               sknnOpts}\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        if useDecisionTree: # Regression tree\n",
        "            opts = commonOpts.copy()\n",
        "            opts.update(dtOpts)\n",
        "            disaggregator = DecisionTreeSharpener(**opts)\n",
        "        else: # Neural network\n",
        "            opts = commonOpts.copy()\n",
        "            opts.update(nnOpts)\n",
        "            disaggregator = NeuralNetworkSharpener(**opts)\n",
        "\n",
        "        # Training the tree\n",
        "        print(\"Training regressor...\")\n",
        "        disaggregator.trainSharpener()\n",
        "        # Applying the newly trained tree to the LR image\n",
        "        print(\"Sharpening...\")\n",
        "        downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
        "        # Performing residual analysis, to ensure that the unsharpened images's exitance is conserved\n",
        "        print(\"Residual analysis...\")\n",
        "        residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
        "                                                                        lowResMaskFilename,\n",
        "                                                                        doCorrection=True)\n",
        "        # Saving the image and its residual \n",
        "        print(\"Saving output...\")\n",
        "        highResFile = gdal.Open(highResFilename)\n",
        "        if correctedImage is not None:\n",
        "            outImage = correctedImage\n",
        "        else:\n",
        "            outImage = downscaledFile\n",
        "\n",
        "        outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
        "                                outImage.GetGeoTransform(),\n",
        "                                outImage.GetProjection(),\n",
        "                                outputFilename)\n",
        "        residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
        "                                        residualImage.GetGeoTransform(),\n",
        "                                        residualImage.GetProjection(),\n",
        "                                        os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
        "                                        os.path.splitext(outputFilename)[1])\n",
        "        files_sharpened.append(file)\n",
        "        outFile = None\n",
        "        residualFile = None\n",
        "        downsaceldFile = None\n",
        "        highResFile = None\n",
        "\n",
        "        print(time.time() - start_time, \"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the ECOSTRESS image is completely included ( i.e. its extent is smaller) in the S2 image, then if desired, it is possible to cut the S2 image to the extent of the ECOSTRESS image, or to an extent of the user's choosing (which also has to be included) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "useDecisionTree = True # You could change this to False if you want to use the Neural Network intead of the Decision tree, not recommended\n",
        "\n",
        "files_sharpened = [] #list of the files sharpened\n",
        "\n",
        "# Loop through the directory of LST images\n",
        "for file in os.listdir(lst_dir_sc) :\n",
        "    if file.endswith('.tif') :\n",
        "        if not os.path.exists(dst_dir) :  # create the output directory if it doesn't exist already\n",
        "                        os.mkdir(dst_dir)\n",
        "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_S2_clipped.tif')) # destination path for the sharpened images\n",
        "        lowResFilename = os.path.join(lst_dir_sc,file)\n",
        "        lr_ds = rasterio.open(lowResFilename)\n",
        "\n",
        "        projwin = [lr_ds.bounds.left,lr_ds.bounds.top,lr_ds.bounds.right,lr_ds.bounds.bottom] # [xmin,ymax,xmax,ymin]\n",
        "        # projwin = [-118.08175, 34.16189, -117.998676, 34.112327] # example of a custom cutout over LA  # this extent has to be fully included in the bounding box !\n",
        "       \n",
        "\n",
        "\n",
        "        hr_img_path_clipped = hr_img_path.replace('.tif',f'_clipped.tif') # also produces a clipped version of the HR image\n",
        "        ds = gdal.Open(hr_img_path)\n",
        "        ds = gdal.Translate(hr_img_path_clipped, ds, projWin = projwin)\n",
        "        ds = None\n",
        "        lr_ds = None\n",
        "\n",
        "        highResFilename = hr_img_path_clipped\n",
        "        lowResMaskFilename = ''\n",
        "\n",
        "\n",
        "        commonOpts = {\"highResFiles\":               [highResFilename],\n",
        "                        \"lowResFiles\":                [lowResFilename],\n",
        "                        \"lowResQualityFiles\":         [lowResMaskFilename],\n",
        "                        \"lowResGoodQualityFlags\":     [], #  no flags for acceptable pixels because no QF file to assert of the quality\n",
        "                        \"cvHomogeneityThreshold\":     0, # the homogeneity threshold will be automatically computed\n",
        "                        \"movingWindowSize\":           0,\n",
        "                        \"disaggregatingTemperature\":  True} # we are dealing with LST\n",
        "        dtOpts =     {\"perLeafLinearRegression\":    True,\n",
        "                        \"linearRegressionExtrapolationRatio\": 0.25} # how much extrapolation we accept from the tree\n",
        "        sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
        "                        'activation':                 'tanh'}\n",
        "        nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
        "                        \"regressorOpt\":               sknnOpts}\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        if useDecisionTree: # Regression tree\n",
        "            opts = commonOpts.copy()\n",
        "            opts.update(dtOpts)\n",
        "            disaggregator = DecisionTreeSharpener(**opts)\n",
        "        else: # Neural network\n",
        "            opts = commonOpts.copy()\n",
        "            opts.update(nnOpts)\n",
        "            disaggregator = NeuralNetworkSharpener(**opts)\n",
        "\n",
        "        # Training the tree\n",
        "        print(\"Training regressor...\")\n",
        "        disaggregator.trainSharpener()\n",
        "        # Applying the newly trained tree to the LR image\n",
        "        print(\"Sharpening...\")\n",
        "        downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
        "        # Performing residual analysis, to ensure that the unsharpened images's exitance is conserved\n",
        "        print(\"Residual analysis...\")\n",
        "        residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
        "                                                                        lowResMaskFilename,\n",
        "                                                                        doCorrection=True)\n",
        "        # Saving the image and its residual \n",
        "        print(\"Saving output...\")\n",
        "        highResFile = gdal.Open(highResFilename)\n",
        "        if correctedImage is not None:\n",
        "            outImage = correctedImage\n",
        "        else:\n",
        "            outImage = downscaledFile\n",
        "\n",
        "        outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
        "                                outImage.GetGeoTransform(),\n",
        "                                outImage.GetProjection(),\n",
        "                                outputFilename)\n",
        "        residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
        "                                        residualImage.GetGeoTransform(),\n",
        "                                        residualImage.GetProjection(),\n",
        "                                        os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
        "                                        os.path.splitext(outputFilename)[1])\n",
        "        files_sharpened.append(file)\n",
        "        outFile = None\n",
        "        residualFile = None\n",
        "        downsaceldFile = None\n",
        "        highResFile = None\n",
        "\n",
        "        print(time.time() - start_time, \"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot one random sharpened image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pick one random sharpened file\n",
        "file = random.choice(files_sharpened)\n",
        "sharpened_file = os.path.join(dst_dir,file.replace('.tif','_sharp_S2.tif'))\n",
        "raw_file = os.path.join(lst_dir_sc,file)\n",
        "with rasterio.open(raw_file,'r') as lr_img :\n",
        "    raw_lst = lr_img.read(1)\n",
        "with rasterio.open(sharpened_file,'r') as shrp_img :\n",
        "    shrp_lst = shrp_img.read(1)\n",
        "\n",
        "custom_cmap = plt.colormaps['rainbow'].copy()\n",
        "custom_cmap.set_under('black')\n",
        "\n",
        "# Plot the ECOSTRESS original product\n",
        "plt.figure(1)\n",
        "plt.imshow(raw_lst,cmap=custom_cmap)\n",
        "plt.axis('off')\n",
        "plt.colorbar(label ='LST(K)')\n",
        "vmin, vmax = plt.gci().get_clim() # save the limits to share them in the second figure\n",
        "plt.title(\"ECOSTRESS LST 70m\")\n",
        "plt.show()\n",
        "\n",
        "# Plot the ECOSTRESS sharpened product\n",
        "plt.figure(2)\n",
        "plt.imshow(shrp_lst,cmap=custom_cmap,clim =(vmin,vmax))\n",
        "plt.axis('off')\n",
        "plt.colorbar(label ='LST(K)')\n",
        "plt.title(\"ECOSTRESS LST sharpened to 30m\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an animation of all the sharpened scenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def title_from_file(filename):\n",
        "  time_info = filename.split('_')[4][3:]\n",
        "  dt = datetime.strptime(time_info, '%Y%j%H%M%S')\n",
        "\n",
        "  formatted_datetime = dt.strftime('%Y-%m-%d at %I:%M %p (UTC)')\n",
        "  title = f\"Land Surface Temperature (K)  {formatted_datetime} \"\n",
        "\n",
        "  return title\n",
        "\n",
        "# Animation creation\n",
        "rc('animation', html='jshtml')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "div = make_axes_locatable(ax)\n",
        "cax = div.append_axes('right', '5%', '5%')\n",
        "\n",
        "LST_sharpened_rasters = [rxr.open_rasterio(os.path.join(dst_dir,file.replace('.tif','_sharp_S2.tif'))).squeeze(\"band\", drop=True) for file in files_sharpened]\n",
        "print([os.path.join(dst_dir,file.replace('.tif','_sharp_S2.tif')) for file in files_sharpened])\n",
        "custom_cmap = plt.colormaps['rainbow'].copy()\n",
        "custom_cmap.set_under('black')\n",
        "\n",
        "\n",
        "frames = []\n",
        "for i in range(len(LST_sharpened_rasters)):\n",
        "  LST_data = LST_sharpened_rasters[i].values\n",
        "  lst_min = LST_data.min()\n",
        "  np.nan_to_num(LST_data,copy = False)\n",
        "  frames.append(LST_data)\n",
        "\n",
        "cv0 = frames[0]\n",
        "im = ax.imshow(cv0,cmap=custom_cmap) \n",
        "cb = fig.colorbar(im, cax=cax)\n",
        "tx = ax.set_title(title_from_file(files_sharpened[i]))\n",
        "\n",
        "def animate(i):\n",
        "  arr = frames[i]\n",
        "  vmax     = np.max(arr[arr>0.0])\n",
        "  vmin     = np.min(arr[arr>0.0])\n",
        "  im.set_data(arr)\n",
        "  im.set_clim(vmin, vmax)\n",
        "  tx.set_text(title_from_file(files_sharpened[i]))\n",
        "  return im,tx\n",
        "\n",
        "\n",
        "ani = animation.FuncAnimation(fig, animate, frames=len(files_sharpened),interval=1000,blit = True, repeat_delay=5000)\n",
        "ani"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "jvsrp_main",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
